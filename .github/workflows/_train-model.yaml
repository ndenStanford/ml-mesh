---
name: Model Training
on  :
  workflow_call:
    inputs:
      environment:
        required: true
        type: string
        description: Environment where code is deployed [prod, stage]
      project:
        required: true
        type: string
        description: Project.
      tag:
        required: true
        type: string
        description: Version tag of image providing the compilation runtime context.
      trained-project:
        required: false
        type: string
        description: Project identifier
      trained-model:
        required: false
        type: string
        description: Model identifier for the project
      sagemaker-runner-type:
        required: true
        default: ml.m4.xlarge # non-gpu
        type: string
        description: Which EC2 instance type to use on Sagemaker. See https://aws.amazon.com/sagemaker/pricing/ for options.
      sagemaker-runner-count:
        required: false
        type: string
        default: 1
      python-version:
        required: false
        type: string
        description: Python version.
      poetry-version:
        required: false
        type: string
        description: Poetry version.
      release:
        required: true
        type: boolean
        default: true
        description: Release flag
      pull-request:
        required: true
        default: true
        type: boolean
        description: Indicates whether this workflow is running for a Pull Request.
      wait:
        required: false
        default: true
        type: boolean
        description: Indicates whether to wait for the job to complete before continuing.
      parameters:
        required: false
        type: string
        description: Parameters associated with the training.
    secrets:
      AWS_ACCOUNT_ID:
        required: true
        description: AWS account ID.
      AWS_DEFAULT_REGION:
        required: true
        description: AWS account region
      AWS_ACCESS_KEY_ID:
        required: true
        description: AWS access key ID.
      AWS_SECRET_ACCESS_KEY:
        required: true
        description: AWS secret access key
      GH_PERSONAL_ACCESS_TOKEN:
        required: true
        description: Github PAT to allow EC2 instance to connect to Github repository content.
      NEPTUNE_API_TOKEN:
        required: true
        description: The API token for the neptune service account managing the model registry.
      ONCLUSIVEML_FEATURE_STORE_MYSQL_HOST:
        required: true
        description: "MySQL host for dev account"
      ONCLUSIVEML_FEATURE_STORE_MYSQL_PASSWORD:
        required: true
        description: "MySQL password for dev account"
      OPENAI_API_KEY:
        required: true
        description: OPENAI Api key.

jobs:
  check-run-criteria:
    name: 'Run criteria: ${{ inputs.project }} training'
    runs-on: ubuntu-22.04
    environment: ${{ inputs.environment }}
    outputs:
      run: ${{ inputs.release || steps.files-changed.outputs.this == 'true' }}
    steps:
      - name: Check out code
        uses: actions/checkout@v4

      - uses: dorny/paths-filter@v3
        id: files-changed
        name: Get a list of modified files.
        with:
          list-files: shell
          filters: |
            this:
              - added | modified: 'projects/${{ inputs.project }}/train/**'

  train-model:
    name: '(Train &) register model: ${{ inputs.project }}'
    needs: check-run-criteria
    runs-on: ubuntu-22.04
    if: ${{ needs.check-run-criteria.outputs.run == 'true' }}
    environment: ${{ inputs.environment }}
    env:
      ONCLUSIVEML_FEATURE_STORE_PROJECT: feature_store_dev
      ONCLUSIVEML_FEATURE_STORE_REDSHIFT_CLUSTER_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
      ONCLUSIVEML_FEATURE_STORE_MYSQL_PASSWORD: ${{ secrets.ONCLUSIVEML_FEATURE_STORE_MYSQL_PASSWORD }}
      ONCLUSIVEML_FEATURE_STORE_MYSQL_HOST: ${{ secrets.ONCLUSIVEML_FEATURE_STORE_MYSQL_HOST }}
      ONCLUSIVEML_FEATURE_STORE_REDSHIFT_USER: github-actions
      ONCLUSIVEML_FEATURE_STORE_REDSHIFT_IAM_ROLE: arn:aws:iam::211212199399:role/kubeflow-cluster-prod-redshift-role

    steps:
      - name: Check out code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python-version }}

      - name: Setup Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ inputs.poetry-version }}
          virtualenvs-create: false

      - name: Install mesh dependencies
        run: poetry install --with ci

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_DEFAULT_REGION }}

      - name: Setup env vars from SSM
        uses: dkershner6/aws-ssm-getparameters-action@v2
        with:
          parameterPairs: "/kubeflow/${{ inputs.environment }}/kubeflow-db/username = ONCLUSIVEML_FEATURE_STORE_MYSQL_USER, /kubeflow/${{ inputs.environment\
            \ }}/kubeflow-db/port = ONCLUSIVEML_FEATURE_STORE_MYSQL_PORT, /admin/${{ inputs.environment }}/warehouse/dbt/redshift-database = ONCLUSIVEML_FEATURE_STORE_REDSHIFT_DATABASE,\
            \ /admin/${{ inputs.environment }}/warehouse/redshift/cluster-id = ONCLUSIVEML_FEATURE_STORE_REDSHIFT_CLUSTER_ID, /admin/${{ inputs.environment\
            \ }}/warehouse/feast/backend = ONCLUSIVEML_FEATURE_STORE_REDSHIFT_S3_STAGING_DIRECTORY"
          withDecryption: "true"

      - name: Create an s3 path environment variable
        run: |
          # Perform a transformation
          ONCLUSIVEML_FEATURE_STORE_REDSHIFT_S3_STAGING_DIRECTORY="s3://kubeflow-feast-backend-prod/${ONCLUSIVEML_FEATURE_STORE_REDSHIFT_USER}"

          # Set the new environment variable by appending it to the $GITHUB_ENV file
          echo "ONCLUSIVEML_FEATURE_STORE_REDSHIFT_S3_STAGING_DIRECTORY=$ONCLUSIVEML_FEATURE_STORE_REDSHIFT_S3_STAGING_DIRECTORY" >> $GITHUB_ENV

      - name: Run project train component on sagemaker
        run: |
          python bin/sagemaker-run \
            --aws-account-id ${{ secrets.AWS_ACCOUNT_ID }} \
            --aws-region ${{ secrets.AWS_DEFAULT_REGION }} \
            --aws-environment ${{ inputs.environment }} \
            --instance-type ${{ inputs.sagemaker-runner-type}} \
            --instance-count ${{ inputs.sagemaker-runner-count }} \
            --project-name ${{ inputs.project }} \
            --project-component train \
            --image-tag ${{ inputs.tag }} \
            --trained-project ${{ inputs.trained-project }} \
            --trained-model ${{ inputs.trained-model }} \
            --run-configuration-dotenv ./projects/${{ inputs.project }}/train/config/prod.env \
            --neptune-api-token ${{ secrets.NEPTUNE_API_TOKEN }} \
            --save_artifact ${{ !inputs.pull-request }} \
            --parameters ${{ inputs.parameters }} \
            --wait ${{ inputs.wait }} \
            --onclusive-feature-store-project ${ONCLUSIVEML_FEATURE_STORE_PROJECT} \
            --onclusive-feature-store-mysql-user ${ONCLUSIVEML_FEATURE_STORE_MYSQL_USER} \
            --onclusive-feature-store-mysql-port ${ONCLUSIVEML_FEATURE_STORE_MYSQL_PORT} \
            --onclusive-feature-store-mysql-password ${ONCLUSIVEML_FEATURE_STORE_MYSQL_PASSWORD} \
            --onclusive-feature-store-mysql-host ${ONCLUSIVEML_FEATURE_STORE_MYSQL_HOST} \
            --onclusive-feature-store-redshift-cluster-region ${{ secrets.AWS_DEFAULT_REGION }} \
            --onclusive-feature-store-redshift-user ${ONCLUSIVEML_FEATURE_STORE_REDSHIFT_USER} \
            --onclusive-feature-store-redshift-iam-role ${ONCLUSIVEML_FEATURE_STORE_REDSHIFT_IAM_ROLE} \
            --onclusive-feature-store-redshift-database ${ONCLUSIVEML_FEATURE_STORE_REDSHIFT_DATABASE} \
            --onclusive-feature-store-redshift-cluster-id ${ONCLUSIVEML_FEATURE_STORE_REDSHIFT_CLUSTER_ID} \
            --onclusive-feature-store-redshift-s3-staging-directory ${ONCLUSIVEML_FEATURE_STORE_REDSHIFT_S3_STAGING_DIRECTORY} \
            --open-api-key ${{ secrets.OPENAI_API_KEY }} \
            python -m src.train_model

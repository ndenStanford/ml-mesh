---

services:
  # ===========================================================
  # PYTHON BASE
  # ===========================================================
  python-base:
    build:
      context: ..
      dockerfile: ./docker/python-base/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        IMAGE_TAG: ${IMAGE_TAG}
        IMAGE_NAME: python-base
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/python-base:${IMAGE_TAG}

  # ===========================================================
  # FASTAPI SERVE
  # ===========================================================ech

  fastapi-serve:
    build:
      context: ..
      dockerfile: ./docker/fastapi-serve/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        IMAGE_TAG: ${IMAGE_TAG}
        IMAGE_NAME: fastapi-serve
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/fastapi-serve:${IMAGE_TAG}
    depends_on:
      - python-base

  # ===========================================================
  # GPU BASE
  # ===========================================================
  gpu-base:
    build:
      context: ..
      dockerfile: ./docker/gpu-base/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        IMAGE_NAME: gpu-base
        IMAGE_TAG: ${IMAGE_TAG}
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gpu-base:${IMAGE_TAG}

  gpu-base-tests:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
            # that's the closest analogue to --gpus; provide
            # an integer amount of devices or 'all'
              count: 1
            # Devices are reserved using a list of capabilities, making
            # capabilities the only required field. A device MUST
            # satisfy all the requested capabilities for a successful
            # reservation.
              capabilities: [gpu]
    volumes:
      - type: bind
        source: gpu-base/tests
        target: /docker/gpu-base/tests
    command: [pytest, tests/core, -ra, -vv, --capture=no]
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gpu-base:${IMAGE_TAG}

  # ===========================================================
  # GPU TRAIN
  # ===========================================================
  gpu-train:
    build:
      context: ..
      dockerfile: ./docker/gpu-train/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        IMAGE_TAG: ${IMAGE_TAG}
        IMAGE_NAME: gpu-train
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gpu-train:${IMAGE_TAG}

  gpu-train-tests:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
            # that's the closest analogue to --gpus; provide
            # an integer amount of devices or 'all'
              count: 1
            # Devices are reserved using a list of capabilities, making
            # capabilities the only required field. A device MUST
            # satisfy all the requested capabilities for a successful
            # reservation.
              capabilities: [gpu]
    volumes:
      - type: bind
        source: gpu-train/tests
        target: /docker/gpu-train/tests
    command: [pytest, tests/core, -ra, -vv, --capture=no]
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gpu-train:${IMAGE_TAG}

  # ===========================================================
  # NEURON COMPILE
  # ===========================================================

  neuron-compile:
    build:
      context: ..
      dockerfile: ./docker/neuron-compile/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        IMAGE_TAG: ${IMAGE_TAG}
        IMAGE_NAME: neuron-compile
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/neuron-compile:${IMAGE_TAG}
    depends_on:
      - python-base

  neuron-compile-tests:
    devices:
      - /dev/neuron0:/dev/neuron0
    volumes:
      - type: bind
        source: neuron-compile/tests
        target: /docker/neuron-compile/tests
    environment:
      NEURON_COMPILE_OUTPUT_DIR: ./tests/output_compile #  ~ /docker/neuron-compile/tests/output_compile in container
    command: [pytest, tests/core, -ra, -vv, --capture=no]
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/neuron-compile:${IMAGE_TAG}
    depends_on:
      - neuron-compile

  # ===========================================================
  # NEURON INFERENCE
  # ===========================================================

  # NOTE: The neuron-inference image generates its own neuron compiled artifacts during the build
  # stage, which it picks up when running the tests. The /docker/neuron-inference/tests/input_inference
  # container directory must not be overriden by bind mounts.
  neuron-inference:
    build:
      context: ..
      dockerfile: ./docker/neuron-inference/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        IMAGE_TAG: ${IMAGE_TAG}
        IMAGE_NAME: neuron-inference
        NEURON_COMPILE_OUTPUT_DIR: tests/input_inference # /docker/neuron-inference/tests/input_inference in container
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/neuron-inference:${IMAGE_TAG}
    depends_on:
      - python-base

  neuron-inference-tests:
    devices:
      - /dev/neuron0:/dev/neuron0
    volumes:
      - type: bind
        source: neuron-inference/tests/core
        target: /docker/neuron-inference/tests/core
    environment:
      NEURON_COMPILE_OUTPUT_DIR: ./tests/input_inference # must match the "NEURON_COMPILE_OUTPUT_DIR" build argument, i.e. /docker/neuron-inference/tests/input_inference in container
    command: [pytest, tests/core, -ra, -vv, --capture=no, -m, inference]
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/neuron-inference:${IMAGE_TAG}
    depends_on:
      - neuron-inference

  # ===========================================================
  # KUBEFLOW JUPYTER
  # ===========================================================

  kubeflow-jupyter:
    build:
      context: ..
      dockerfile: ./docker/kubeflow-jupyter/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        IMAGE_TAG: ${IMAGE_TAG}
        IMAGE_NAME: kubeflow-jupyter
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-2.amazonaws.com/kubeflow-jupyter:${IMAGE_TAG}
    ports:
      - 8888:8888
    depends_on:
      - python-base

  # ===========================================================
  # KUBEFLOW TORCH CPU
  # ===========================================================

  kubeflow-torch-cpu:
    build:
      context: ..
      dockerfile: ./docker/kubeflow-torch-cpu/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        IMAGE_TAG: ${IMAGE_TAG}
        IMAGE_NAME: kubeflow-torch-cpu
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-2.amazonaws.com/kubeflow-torch-cpu:${IMAGE_TAG}
    ports:
      - 8888:8888
    depends_on:
      - kubeflow-jupyter

  # ===========================================================
  # KUBEFLOW DATA SCIENCE
  # ===========================================================

  kubeflow-data-science:
    build:
      context: ..
      dockerfile: ./docker/kubeflow-data-science/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        IMAGE_TAG: ${IMAGE_TAG}
        IMAGE_NAME: kubeflow-data-science
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-2.amazonaws.com/kubeflow-data-science:${IMAGE_TAG}
    ports:
      - 8888:8888
    depends_on:
      - kubeflow-torch-cpu

  # ===========================================================
  # KUBEFLOW TORCH GPU
  # ===========================================================

  kubeflow-torch-gpu:
    build:
      context: ..
      dockerfile: ./docker/kubeflow-torch-gpu/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        IMAGE_TAG: ${IMAGE_TAG}
        IMAGE_NAME: kubeflow-torch-gpu
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-2.amazonaws.com/kubeflow-torch-gpu:${IMAGE_TAG}
    ports:
      - 8888:8888

  # ===========================================================
  # DASK BASE
  # ===========================================================

  dask-base:
    build:
      context: ..
      dockerfile: ./docker/dask-base/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        IMAGE_TAG: ${IMAGE_TAG}
        IMAGE_NAME: dask-base
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-2.amazonaws.com/dask-base:${IMAGE_TAG}

  dask-scheduler:
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-2.amazonaws.com/dask-base:${IMAGE_TAG}
    ports:
      - 8786:8786
      - 8787:8787
    command: [dask-scheduler]
    depends_on:
      - dask-base

  dask-worker:
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-2.amazonaws.com/dask-base:${IMAGE_TAG}
    hostname: dask-worker
    command: [dask-worker, tcp://scheduler:8786]
    depends_on:
      - dask-base

  # ===========================================================
  # KUBEFLOW TORCH INF
  # ===========================================================

  kubeflow-torch-inf:
    build:
      context: ..
      dockerfile: ./docker/kubeflow-torch-inf/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        IMAGE_TAG: ${IMAGE_TAG}
        IMAGE_NAME: kubeflow-torch-inf
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-2.amazonaws.com/kubeflow-torch-inf:${IMAGE_TAG}
    ports:
      - 8888:8888

  # ===========================================================
  # BEAM BACKFILL
  # ===========================================================

  beam-backfill:
    build:
      context: ..
      dockerfile: ./docker/beam-backfill/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        IMAGE_TAG: ${IMAGE_TAG}
        IMAGE_NAME: beam-backfill
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/beam-backfill:${IMAGE_TAG}

  # ===========================================================
  # BEAM WORKER
  # ===========================================================

  beam-worker:
    stdin_open: true
    tty: true
    entrypoint: [/bin/bash]
    build:
      context: ..
      dockerfile: ./docker/beam-worker/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        IMAGE_TAG: ${IMAGE_TAG}
        IMAGE_NAME: beam-worker
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/beam-worker:${IMAGE_TAG}

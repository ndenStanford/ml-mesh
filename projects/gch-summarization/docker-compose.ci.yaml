---
version      : '3.9'

services     :
  # =============================================
  # TRAIN
  # =============================================

  train:
    build:
      context: ../../
      dockerfile: projects/gch-summarization/train/Dockerfile
      target: ${TARGET_BUILD_STAGE:-production}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        PROJECT: gch-summarization
        COMPONENT: train
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v23.11.3}
    volumes:
      - type: bind
        source: train/src
        target: /projects/gch-summarization/train/src
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gch-summarization-train:${IMAGE_TAG:-latest}
    command: [python, -m, src.train_model]
    profiles: [train]
    environment:
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    env_file: train/config/prod.env
    hostname: onclusive-ml
    networks: [onclusive-net]

  train-unit:
    volumes:
      - type: bind
        source: train/src
        target: /projects/gch-summarization/train/src
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gch-summarization-train:${IMAGE_TAG:-latest}
    command: [pytest, tests/unit, -ra, -vv, --capture=no]
    profiles: [train, unit]
    environment:
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
    hostname: onclusive-ml
    networks: [onclusive-net]

  # =============================================
  # SERVE
  # =============================================

  # serving image
  serve:
    volumes:
      - serve-vol:/projects/gch-summarization/serve/models
    build:
      context: ../../
      dockerfile: projects/gch-summarization/serve/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        PROJECT: gch-summarization
        COMPONENT: serve
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v23.11.3}
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gch-summarization-serve:${IMAGE_TAG}
    command: [python, -m, src.serve.__main__]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      ONCLUSIVEML_SERVING_LOGCONFIG_SERVICE: gch-summarization-serve
      ONCLUSIVEML_SERVING_LOGCONFIG_LEVEL: 20
      ONCLUSIVEML_SERVING_LOGCONFIG_JSON_FORMAT: yes
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SUM-TRAINED-88
      ONCLUSIVEML_SERVING_UVICORN_APP: src.serve.__main__:model_server
      ONCLUSIVEML_SERVING_UVICORN_HTTP_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
      ONCLUSIVEML_SERVING_READINESS_SAMPLE_INFERENCE: false
      ONCLUSIVEML_SERVING_LIVENESS_SAMPLE_INFERENCE: false
      NEPTUNE_PROJECT: onclusive/gch-summarization
      NEPTUNE_MODEL_ID: SUM-TRIANED
    profiles: [serve, functional, load]
    ports:
      - 8000:8000
    hostname: onclusiveml
    networks:
      - onclusive-net
    healthcheck:
      test: [CMD, curl, -f, http://serve:8000/gch-summarization/v1/ready]
      interval: 10s
      retries: 5
      start_period: 5s
      timeout: 10s

  # utility service: downloading the compiled model artifact that will be served
  serve-download-model:
    volumes:
      - serve-vol:/projects/gch-summarization/serve/models
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gch-summarization-serve:${IMAGE_TAG}
    command: [python, -m, src.download]
    profiles: [serve, integration, functional, load]
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
      NEPTUNE_CLIENT_MODE: read-only
      NEPTUNE_PROJECT: onclusive/gch-summarization
      NEPTUNE_MODEL_ID: SUM-TRAINED
      NEPTUNE_MODEL_VERSION_ID: SUM-TRAINED-79
      ONCLUSIVEML_TRACKING_BACKEND_USE_S3_BACKEND: yes
      ONCLUSIVEML_TRACKING_BACKEND_S3_BACKEND_BUCKET: onclusive-model-store-stage
      ONCLUSIVEML_TRACKING_LOGGER_LEVEL: 20
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SUM-TRAINED-88
    hostname: onclusiveml
    networks: [onclusive-net]

  # unit tests
  # - do NOT include model artifact
  # - do NOT include REST model server process
  serve-unit:
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gch-summarization-serve:${IMAGE_TAG}
    command: [pytest, tests/unit, -ra, -vv, --capture=no]
    profiles: [unit]
    hostname: onclusiveml
    environment:
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SUN-TRAINED-79
      ONCLUSIVEML_SERVING_UVICORN_HTTP_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
      ONCLUSIVEML_TRACKING_LOGGER_LEVEL: 20 # 10=DEBUG
      NEPTUNE_PROJECT: onclusive/gch-summarization
      NEPTUNE_MODEL_ID: SUM-TRAINED
      NEPTUNE_MODEL_VERSION_ID: SUM-TRAINED-79
    networks:
      - onclusive-net

  # integration tests
  # - include model artifact
  # - do NOT include REST model server process
  serve-integration:
    volumes:
      - serve-vol:/projects/gch-summarization/serve/models
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gch-summarization-serve:${IMAGE_TAG}
    command: [pytest, tests/integration, -ra, -vv, --capture=no]
    environment:
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SUM-TRAINED-88
      ONCLUSIVEML_SERVING_UVICORN_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
      NEPTUNE_PROJECT: onclusive/gch-summarization
      NEPTUNE_MODEL_ID: SUM-TRAINED
    profiles: [integration]
    hostname: onclusiveml
    networks:
      - onclusive-net

  # functional tests
  # - include model artifact
  # - include REST model server process
  serve-functional:
    volumes:
      - serve-vol:/projects/gch-summarization/serve/models
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gch-summarization-serve:${IMAGE_TAG}
    command: [pytest, tests/functional, -ra, -vv, --capture=no]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SUM-TRAINED-88
      ONCLUSIVEML_SERVING_UVICORN_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
      NEPTUNE_PROJECT: onclusive/gch-summarization
      NEPTUNE_MODEL_ID: SUM-TRAINED
    profiles: [functional]
    hostname: onclusiveml
    networks:
      - onclusive-net
    depends_on:
      serve:
        condition: service_healthy

  # load tests
  # - include model artifact
  # - include REST model server process
  serve-load:
    volumes:
      - serve-vol:/projects/gch-summarization/serve/models
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gch-summarization-serve:${IMAGE_TAG}
    command: [pytest, tests/load, -ra, -vv, --capture=no]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
    # serving params
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SUM-TRAINED-88
      ONCLUSIVEML_SERVING_UVICORN_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
      # load test params
      ONCLUSIVEML_SERVING_NUM_USERS: 2 # numbers of users in load test
      ONCLUSIVEML_SERVING_SPAWN_RATE: 2 # per second spawn rate of clients until `num_users` is reached
      ONCLUSIVEML_SERVING_HOST: http://serve:8000 # base url of the host
      ONCLUSIVEML_SERVING_RESET_STATS: No
      ONCLUSIVEML_SERVING_RUN_TIME: 45
      ONCLUSIVEML_SERVING_LOGLEVEL: INFO
      NEPTUNE_PROJECT: onclusive/gch-summarization
      NEPTUNE_MODEL_ID: SUM-TRAINED
    profiles: [load]
    hostname: onclusiveml
    networks:
      - onclusive-net
    depends_on:
      serve:
        condition: service_healthy

  # utility service: uploading the relevant test results to the model registry
  serve-upload-results:
    volumes:
      - serve-vol:/projects/gch-summarization/serve/models
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gch-summarization-serve:${IMAGE_TAG}
    command: [python, -m, src.upload]
    profiles: [serve]
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
      NEPTUNE_CLIENT_MODE: async
      NEPTUNE_PROJECT: onclusive/gch-summarization
      NEPTUNE_MODEL_ID: SUM-TRAINED
      NEPTUNE_MODEL_VERSION_ID: SUM-TRAINED-79
      ONCLUSIVEML_TRACKING_BACKEND_USE_S3_BACKEND: yes
      ONCLUSIVEML_TRACKING_BACKEND_S3_BACKEND_BUCKET: onclusive-model-store-stage
      ONCLUSIVEML_TRACKING_LOGGER_LEVEL: 20
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SUM-TRAINED-88
      DOCKER_IMAGE_NAME: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gch-summarization-serve
      DOCKER_IMAGE_TAG: ${IMAGE_TAG}
      DOCKER_COMPOSE_ENVIRONMENT: ${ENVIRONMENT}
      GITHUB_REPOSITORY: ${GITHUB_REPOSITORY}
      GITHUB_ACTOR: ${GITHUB_ACTOR}
      GITHUB_ENV: ${GITHUB_ENV}
      GITHUB_WORKFLOW: ${GITHUB_WORKFLOW}
      GITHUB_JOB: ${GITHUB_JOB}
      GITHUB_REF: ${GITHUB_REF}
      GITHUB_BASE_REF: ${GITHUB_BASE_REF}
      GITHUB_HEAD_REF: ${GITHUB_HEAD_REF}
      GITHUB_SHA: ${GITHUB_SHA}
      GITHUB_EVENT_NAME: ${GITHUB_EVENT_NAME}
      GITHUB_RUN_ID: ${GITHUB_RUN_ID}
      GITHUB_RUN_NUMBER: ${GITHUB_RUN_NUMBER}
      RUNNER_ARCH: ${RUNNER_ARCH}
      RUNNER_NAME: ${RUNNER_NAME}
      RUNNER_OS: ${RUNNER_OS}
    hostname: onclusive-ml
    networks: [onclusive-net]

# =============================================
# BACKFILL
# =============================================

backfill     :
  build:
    context: ../../
    dockerfile: projects/gch-summarization/backfill/Dockerfile
    target: ${TARGET_BUILD_STAGE:-development}
    network: host
    args:
      AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
      PROJECT: gch-summarization
      COMPONENT: backfill
      BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v24.1.6}
  volumes:
    - backfill-vol:/tmp/beam-artifact-staging
    - type: bind
      source: backfill/src
      target: /projects/gch-summarization/backfill/src
  image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gch-summarization-backfill:${IMAGE_TAG}
  entrypoint: [python, -m, src.backfill.__main__]
  profiles: [backfill]
  network_mode: service:taskmanager
  environment:
    HOST: internal.api.ml.stage.onclusive.com
    NAMESPACE: gch-summarization
    VERSION: 1
    API_KEY: ${INTERNAL_ML_ENDPOINT_API_KEY}
    SECURE: true
    JOB_NAME: gch-summarization-backfill
    RUNNER: PortableRunner
    STREAMING: true
    ARTIFACT_ENDPOINT: jobserver:8098
    JOB_ENDPOINT: jobserver:8099
    ENVIRONMENT_TYPE: LOOPBACK
    SOURCE_TOPIC: beam-input
    TARGET_TOPIC: beam-output
    BOOTSTRAP_SERVERS: kafka:9092
    GROUP_ID: notification_consumer_group
    AUTO_OFFSET_RESET: earliest
  depends_on:
    - jobserver
    - kafka
    - zookeeper

backfill-unit:
  volumes:
    - type: bind
      source: backfill
      target: /projects/gch-summarization/backfill
  image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/gch-summarization-backfill:${IMAGE_TAG}
  command: [pytest, tests/unit, -ra, -vv, --capture=no, -s]
  profiles: [unit]
  environment:
    HOST: test.onclusive.com
    NAMESPACE: gch-summarization
    VERSION: 1
    API_KEY: test
    SECURE: true
    JOB_NAME: gch-summarization-backfill
    RUNNER: PortableRunner
    STREAMING: true
    ARTIFACT_ENDPOINT: jobserver:8098
    JOB_ENDPOINT: jobserver:8099
    ENVIRONMENT_TYPE: LOOPBACK
    SOURCE_TOPIC: test-input
    TARGET_TOPIC: test-output
    BOOTSTRAP_SERVERS: kafka:9092
    GROUP_ID: notification_consumer_group
    AUTO_OFFSET_RESET: earliest
  hostname: onclusive-ml
  networks: [onclusive-net]

jobmanager   :
  image: apache/flink:1.16-scala_2.12-java11
  command: [jobmanager]
  ports:
    - 8081:8081
  profiles: [backfill]
  networks: [onclusive-net]
  environment:
    FLINK_PROPERTIES: |
      jobmanager.rpc.address: jobmanager
      parallelism.default: 1

taskmanager  :
  image: apache/flink:1.16-scala_2.12-java11
  scale: 1
  depends_on:
    - jobmanager
  command: [taskmanager]
  ports:
    - 8100-8200:8100-8200
  profiles: [backfill]
  networks: [onclusive-net]
  environment:
    FLINK_PROPERTIES: |
      jobmanager.rpc.address: jobmanager
      taskmanager.numberOfTaskSlots: 2
      parallelism.default: 1
  volumes:
    - backfill-vol:/tmp/beam-artifact-staging

jobserver    :
  image: apache/beam_flink1.16_job_server:2.49.0
  command:
    - --flink-master=jobmanager:8081
  ports:
    - 8097:8097
    - 8098:8098
    - 8099:8099
  depends_on:
    - jobmanager
  profiles: [backfill]
  networks: [onclusive-net]
  volumes:
    - backfill-vol:/tmp/beam-artifact-staging

zookeeper    :
  image: confluentinc/cp-zookeeper
  profiles: [backfill]
  networks: [onclusive-net]
  ports:
    - 2181:2181
  environment:
    ZOOKEEPER_CLIENT_PORT: 2181
    ZOOKEEPER_TICK_TIME: 2000
    ZOOKEEPER_SYNC_LIMIT: 2

kafka        :
  image: confluentinc/cp-kafka:6.1.13
  profiles: [backfill]
  networks: [onclusive-net]
  ports:
    - 9092:9092
    - 9094:9094
  depends_on:
    - zookeeper
  environment:
    KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,OUTSIDE://0.0.0.0:9094
    KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://localhost:9094
    LAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://localhost:9094
    KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
    KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    KAFKA_CREATE_TOPICS: beam-input:1:1,beam-output:1:1
    KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    TOPIC_AUTO_CREATE: true

networks     :
  onclusive-net:

volumes      :
  compile-vol:
  serve-vol:
  backfill-vol:

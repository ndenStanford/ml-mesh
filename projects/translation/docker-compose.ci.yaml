---
version : '3.9'

services:
  # =============================================
  # SERVE
  # =============================================
  serve:
    build:
      context: ../../
      dockerfile: projects/translation/serve/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        PROJECT: translation
        COMPONENT: serve
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v23.11.3}
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/translation-serve:${IMAGE_TAG}
    command: [python, -m, src.serve.__main__]
    environment:
      ONCLUSIVEML_SERVING_LOGCONFIG_SERVICE: translation-serve
      ONCLUSIVEML_SERVING_LOGCONFIG_LEVEL: 20
      ONCLUSIVEML_SERVING_LOGCONFIG_JSON_FORMAT: yes
      ONCLUSIVEML_SERVING_UVICORN_APP: src.serve.__main__:model_server
      ONCLUSIVEML_SERVING_UVICORN_HTTP_PORT: 8000
      ONCLUSIVEML_SERVING_UVICORN_WORKERS: 1
      ONCLUSIVEML_SERVING_API_VERSION: v1
    profiles: [serve, functional]
    ports:
      - 8000:8000
    hostname: onclusiveml
    networks:
      - onclusive-net
    healthcheck:
      test: [CMD, curl, -f, http://serve:8000/translation/v1/ready]
      interval: 10s
      retries: 5
      start_period: 5s
      timeout: 10s


  serve-unit:
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/translation-serve:${IMAGE_TAG}
    command: [pytest, tests/unit, -ra, -vv, --capture=no]
    profiles: [unit]
    hostname: onclusiveml
    environment:
      ONCLUSIVEML_SERVING_UVICORN_HTTP_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
      ONCLUSIVEML_TRACKING_LOGGER_LEVEL: 20 # 10=DEBUG
    networks:
      - onclusive-net

  serve-functional:
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/translation-serve:${IMAGE_TAG}
    command: [pytest, tests/functional, -ra, -vv, --capture=no]
    environment:
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SCORING-COMPILED-1
      ONCLUSIVEML_SERVING_UVICORN_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
    profiles: [functional]
    hostname: onclusiveml
    networks:
      - onclusive-net
    depends_on:
      serve:
        condition: service_healthy

networks:
  onclusive-net:

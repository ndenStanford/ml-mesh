---
version : '3.9'

services:
  # =============================================
  # SERVE
  # =============================================
  serve:
    build:
      context: ../../
      dockerfile: projects/topic-summarization/serve/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      cache_to:
        - type=s3,bucket=ecr-cache-${DEPLOYMENT},region=us-east-1,name=topic-summarization-serve,mode=min
      cache_from:
        - type=s3,bucket=ecr-cache-${DEPLOYMENT},region=us-east-1,name=topic-summarization-serve
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        PROJECT: topic-summarization
        COMPONENT: serve
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v24.4.2}
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/topic-summarization-serve:${IMAGE_TAG:-latest}
    command: [python, -m, src.serve.__main__]
    profiles: [serve, integration, functional]
    ports:
      - 8888:8888
    environment:
      ONCLUSIVEML_SERVING_LOGCONFIG_SERVICE: topic-summarization-serve
      ONCLUSIVEML_SERVING_LOGCONFIG_LEVEL: 20
      ONCLUSIVEML_SERVING_LOGCONFIG_JSON_FORMAT: yes
      ONCLUSIVEML_SERVING_UVICORN_APP: src.serve.__main__:model_server
      ONCLUSIVEML_SERVING_UVICORN_PORT: 8888
      ONCLUSIVEML_SERVING_API_VERSION: v1
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      PROMPT_API: http://prompt-backend:4000
      INTERNAL_ML_ENDPOINT_API_KEY: ${INTERNAL_ML_ENDPOINT_API_KEY:-1234}
      MULTIPROCESS_WORKER: 5
      MEDIA_CLIENT_ID: ${MEDIA_CLIENT_ID}
      MEDIA_CLIENT_SECRET: ${MEDIA_CLIENT_SECRET}
      ELASTICSEARCH_KEY: ${ELASTICSEARCH_KEY}
      ENVIRONMENT: prod
    env_file: serve/config/prod.env
    healthcheck:
      test: [CMD, curl, -f, http://serve:8888/topic-summarization/v1/ready]
      interval: 10s
      retries: 5
      start_period: 5s
      timeout: 10s
    depends_on:
      prompt-backend:
        condition: service_healthy
    hostname: onclusiveml
    networks:
      - onclusive-net

  serve-unit:
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/topic-summarization-serve:${IMAGE_TAG:-latest}
    command: [pytest, tests/unit, -ra, -vv, --capture=no]
    profiles: [unit]
    hostname: onclusiveml
    networks:
      - onclusive-net

  serve-integration:
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/topic-summarization-serve:${IMAGE_TAG:-latest}
    command: [pytest, tests/integration, -ra, -vv, --capture=no]
    profiles: [integration]
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      PROMPT_API: http://prompt-backend:4000
      INTERNAL_ML_ENDPOINT_API_KEY: ${INTERNAL_ML_ENDPOINT_API_KEY:-1234}
      MEDIA_CLIENT_ID: ${MEDIA_CLIENT_ID}
      MEDIA_CLIENT_SECRET: ${MEDIA_CLIENT_SECRET}
      ELASTICSEARCH_KEY: ${ELASTICSEARCH_KEY}
      DYNAMODB_HOST: http://dynamodb:8000
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      ENVIRONMENT: prod
    env_file: serve/config/test.env
    depends_on:
      prompt-backend:
        condition: service_healthy
    hostname: onclusiveml
    networks:
      - onclusive-net

  # functional tests
  serve-functional:
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/topic-summarization-serve:${IMAGE_TAG:-latest}
    command: [pytest, tests/functional, -ra, -vv, --capture=no]
    profiles: [functional]
    environment:
      ONCLUSIVEML_SERVING_UVICORN_PORT: 8888
      ONCLUSIVEML_SERVING_API_VERSION: v1
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      PROMPT_API: http://prompt-backend:4000
      INTERNAL_ML_ENDPOINT_API_KEY: ${INTERNAL_ML_ENDPOINT_API_KEY:-1234}
      MEDIA_CLIENT_ID: ${MEDIA_CLIENT_ID}
      MEDIA_CLIENT_SECRET: ${MEDIA_CLIENT_SECRET}
      ELASTICSEARCH_KEY: ${ELASTICSEARCH_KEY}
      DYNAMODB_HOST: http://dynamodb:8000
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      ENVIRONMENT: prod
    env_file: serve/config/test.env
    depends_on:
      serve:
        condition: service_healthy
      prompt-backend:
        condition: service_healthy
    hostname: onclusiveml
    networks:
      - onclusive-net

  prompt-backend:
    build:
      context: ../../
      dockerfile: apps/prompt/backend/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        APP_NAME: prompt
        APP_COMPONENT: backend
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v24.4.2}
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/prompt-backend:${IMAGE_TAG}
    command: [uvicorn, src.app:app, --host, 0.0.0.0, --port, '4000', --reload, --log-level, debug]
    profiles: [serve, integration, functional]
    ports:
      - 4000:4000
    environment:
      ENVIRONMENT: prod
      OPENAI_API_KEY: ${OPENAI_API_KEY:-none}
      DOCS_URL: /docs
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-anything}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-anything}
      REDIS_CONNECTION_STRING: redis://redisdb:6379
      DYNAMODB_HOST: http://dynamodb:8000
      PROMPT_REGISTRY_APP_ID: ${PROMPT_REGISTRY_APP_ID}
      PROMPT_REGISTRY_APP_PRIVATE_KEY: ${PROMPT_REGISTRY_APP_PRIVATE_KEY}
    depends_on:
      dynamodb:
        condition: service_healthy
      redisdb:
        condition: service_healthy
    healthcheck:
      # NOTE: This hack is required so that the integration tests only start when the
      # databse is ready to receive requests.
      test: [CMD-SHELL, sleep 10s || exit 1]
      interval: 30s
      timeout: 20s
      retries: 5
      start_period: 50s
    networks:
      - onclusive-net

  dynamodb:
    command: -jar DynamoDBLocal.jar -sharedDb
    image: amazon/dynamodb-local:latest
    restart: always
    expose:
      - 8000
    ports:
      - 8000:8000
    profiles: [serve, integration, functional]
    healthcheck:
      # NOTE: This hack is required so that the integration tests only start when the
      # databse is ready to receive requests.
      test: [CMD-SHELL, sleep 3s || exit 1]
      interval: 5s
      retries: 5
      start_period: 5s
      timeout: 10s
    networks:
      - onclusive-net

  redisdb:
    image: redis:7.0
    restart: always
    expose:
      - 6379
    ports:
      - 6379:6379
    profiles: [serve, integration, functional]
    healthcheck:
      # NOTE: This hack is required so that the integration tests only start when the
      # databse is ready to receive requests.
      test: [CMD-SHELL, sleep 3s || exit 1]
      interval: 5s
      retries: 5
      start_period: 5s
      timeout: 10s
    networks:
      - onclusive-net

  # =============================================
  # BACKFILL
  # =============================================

  backfill:
    build:
      context: ../../
      dockerfile: projects/topic-summarization/backfill/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      cache_to:
        - type=s3,bucket=ecr-cache-${DEPLOYMENT},region=us-east-1,name=topic-summarization-backfill,mode=min
      cache_from:
        - type=s3,bucket=ecr-cache-${DEPLOYMENT},region=us-east-1,name=topic-summarization-backfill
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        PROJECT: topic-summarization
        COMPONENT: backfill
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v24.1.6}
    volumes:
      - type: bind
        source: backfill/src
        target: /projects/topic-summarization/backfill/src
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/topic-summarization-backfill:${IMAGE_TAG}
    entrypoint: [python, -m, src.backfill.__main__]
    profiles: [backfill]
    network_mode: service:taskmanager
    environment:
      HOST: internal.api.ml.stage.onclusive.com
      NAMESPACE: topic-summarization
      VERSION: 1
      API_KEY: ${INTERNAL_ML_ENDPOINT_API_KEY}
      SECURE: true
      JOB_NAME: topic-summarization-backfill
      RUNNER: PortableRunner
      STREAMING: true
      ARTIFACT_ENDPOINT: jobserver:8098
      JOB_ENDPOINT: jobserver:8099
      ENVIRONMENT_TYPE: LOOPBACK
      SOURCE_TOPIC: beam-input
      TARGET_TOPIC: beam-output
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: notification_consumer_group
      AUTO_OFFSET_RESET: earliest
    depends_on:
      - jobserver
      - kafka
      - zookeeper

  backfill-unit:
    volumes:
      - type: bind
        source: backfill
        target: /projects/topic-summarization/backfill
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/topic-summarization-backfill:${IMAGE_TAG}
    command: [pytest, tests/unit, -ra, -vv, --capture=no, -s]
    profiles: [unit]
    environment:
      HOST: test.onclusive.com
      NAMESPACE: topic-summarization
      VERSION: 1
      API_KEY: test
      SECURE: true
      JOB_NAME: topic-summarization-backfill
      RUNNER: PortableRunner
      STREAMING: true
      ARTIFACT_ENDPOINT: jobserver:8098
      JOB_ENDPOINT: jobserver:8099
      ENVIRONMENT_TYPE: LOOPBACK
      SOURCE_TOPIC: test-input
      TARGET_TOPIC: test-output
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: notification_consumer_group
      AUTO_OFFSET_RESET: earliest
    hostname: onclusive-ml
    networks: [onclusive-net]

  jobmanager:
    image: apache/flink:1.16-scala_2.12-java11
    command: [jobmanager]
    ports:
      - 8081:8081
    profiles: [backfill]
    networks: [onclusive-net]
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: jobmanager
        parallelism.default: 1

  taskmanager:
    image: apache/flink:1.16-scala_2.12-java11
    scale: 1
    depends_on:
      - jobmanager
    command: [taskmanager]
    ports:
      - 8100-8200:8100-8200
    profiles: [backfill]
    networks: [onclusive-net]
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 2
        parallelism.default: 1
    volumes:
      - backfill-volume:/tmp/beam-artifact-staging

  jobserver:
    image: apache/beam_flink1.16_job_server:2.49.0
    command:
      - --flink-master=jobmanager:8081
    ports:
      - 8097:8097
      - 8098:8098
      - 8099:8099
    depends_on:
      - jobmanager
    profiles: [backfill]
    networks: [onclusive-net]
    volumes:
      - backfill-volume:/tmp/beam-artifact-staging

  zookeeper:
    image: confluentinc/cp-zookeeper
    profiles: [backfill]
    networks: [onclusive-net]
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2

  kafka:
    image: confluentinc/cp-kafka:6.1.13
    profiles: [backfill]
    networks: [onclusive-net]
    ports:
      - 9092:9092
      - 9094:9094
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,OUTSIDE://0.0.0.0:9094
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://localhost:9094
      LAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CREATE_TOPICS: beam-output:1:1,beam-input:1:1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      TOPIC_AUTO_CREATE: true

networks:
  onclusive-net:

volumes :
  backfill-volume:

---
version : '3.9'

services:
  # =============================================
  # TRAIN
  # =============================================

  train:
    volumes:
      - type: bind
        source: train
        target: /projects/sentiment/train
    build:
      context: ../../
      dockerfile: projects/sentiment/train/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        PROJECT: sentiment
        COMPONENT: train
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v23.11.3}
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-train:${IMAGE_TAG:-latest}
    command: [python, -m, src.train_model]
    profiles: [train]
    environment:
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      ONCLUSIVEML_TRACKING_BACKEND_USE_S3_BACKEND: yes
      ONCLUSIVEML_TRACKING_LOGGER_LEVEL: 10
    env_file: train/config/dev.env
    hostname: onclusive-ml
    networks: [onclusive-net]

  train-debug:
    build:
      context: ../../
      dockerfile: projects/sentiment/train/Dockerfile
      target: ${TARGET_BUILD_STAGE:-debugger}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        PROJECT: sentiment
        COMPONENT: train
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v23.11.3}
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-train:${IMAGE_TAG:-latest}
    command: [python, -m, debugpy, --listen, 0.0.0.0:5678, --wait-for-client, -m, src.train_model]
    ports:
      - 5678:5678
    profiles: [debug]
    environment:
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    env_file: train/config/dev.env
    hostname: onclusive-ml
    networks: [onclusive-net]

  train-unit:
    volumes:
      - type: bind
        source: train
        target: /projects/sentiment/train
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-train:${IMAGE_TAG:-latest}
    command: [pytest, tests/unit, -ra, -vv, --capture=no]
    profiles: [unit]
    environment:
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    hostname: onclusive-ml
    networks: [onclusive-net]

  # =============================================
  # COMPILE
  # =============================================

  compile:
    devices:
      - /dev/neuron0:/dev/neuron0
    volumes:
      - type: bind
        source: compile
        target: /projects/sentiment/compile
    build:
      context: ../../
      dockerfile: projects/sentiment/compile/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        PROJECT: sentiment
        COMPONENT: compile
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v23.11.3}
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-compile:${IMAGE_TAG:-latest}
    command: [python, -m, src.compile_model]
    profiles: [compile, unit, integration, pipeline]
    environment:
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
    env_file: compile/config/dev.env
    hostname: onclusive-ml
    networks: [onclusive-net]

  compile-debug:
    devices:
      - /dev/neuron0:/dev/neuron0
    build:
      context: ../../
      dockerfile: projects/sentiment/compile/Dockerfile
      target: ${TARGET_BUILD_STAGE:-debugger}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        PROJECT: sentiment
        COMPONENT: compile
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v23.11.3}
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-compile:${IMAGE_TAG:-latest}
    command:
      - /bin/sh
      - -c
      - |
        python -m src.download_uncompiled_model
        python -m debugpy --listen 0.0.0.0:5678 --wait-for-client -m src.compile_model
    ports:
      - 5678:5678
    profiles: [debug]
    environment:
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    env_file: compile/config/dev.env
    hostname: onclusive-ml
    networks: [onclusive-net]

  compile-unit:
    volumes:
      - type: bind
        source: compile
        target: /projects/sentiment/compile
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-compile:${IMAGE_TAG}
    command: [pytest, tests/unit, -ra, -vv, --capture=no, -s]
    profiles: [unit]
    hostname: onclusive-ml
    networks: [onclusive-net]

  compile-download-model:
    volumes:
      - type: bind
        source: compile/
        target: /projects/sentiment/compile/
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-compile:${IMAGE_TAG}
    command: [python, -m, src.download_uncompiled_model]
    profiles: [pipeline]
    environment:
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    env_file: compile/config/dev.env
    hostname: onclusive-ml
    networks: [onclusive-net]

  compile-validate-model:
    devices:
      - /dev/neuron0:/dev/neuron0
    volumes:
      - type: bind
        source: compile
        target: /projects/sentiment/compile
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-compile:${IMAGE_TAG}
    command: [python, -m, pytest, src/test_compiled_model, -ra, -vvv, --full-trace, --tb=long, --capture=no, -s]
    profiles: [pipeline]
    environment:
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
    env_file: compile/config/dev.env
    hostname: onclusive-ml
    networks: [onclusive-net]

  compile-upload-model:
    volumes:
      - type: bind
        source: compile
        target: /projects/sentiment/compile
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-compile:${IMAGE_TAG}
    command: [python, -m, src.upload_compiled_model]
    profiles: [pipeline]
    environment:
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    hostname: onclusive-ml
    networks: [onclusive-net]

  # =============================================
  # SERVE
  # =============================================

  # serving image
  serve:
    devices:
      - /dev/neuron0:/dev/neuron0
    volumes:
      - type: bind
        source: serve/
        target: /projects/sentiment/serve/
    build:
      context: ../../
      dockerfile: projects/sentiment/serve/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        PROJECT: sentiment
        COMPONENT: serve
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v23.11.3}
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-serve:${IMAGE_TAG}
    command: [python, -m, src.serve.__main__]
    environment:
      ONCLUSIVEML_SERVING_LOGCONFIG_SERVICE: sentiment-serve
      ONCLUSIVEML_SERVING_LOGCONFIG_LEVEL: 10
      ONCLUSIVEML_SERVING_LOGCONFIG_JSON_FORMAT: false
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SEN-COMPILED-46
      ONCLUSIVEML_SERVING_UVICORN_APP: src.serve.__main__:model_server
      ONCLUSIVEML_SERVING_UVICORN_RELOAD: true
      ONCLUSIVEML_SERVING_UVICORN_RELOAD_DIRS: src/serve/
      ONCLUSIVEML_SERVING_UVICORN_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
      ONCLUSIVEML_TRACKING_LOGGER_LEVEL: 20 # 10=DEBUG
      NEPTUNE_PROJECT: onclusive/sentiment
      NEPTUNE_MODEL_ID: SEN-COMPILED
    profiles: [serve, functional, load]
    ports:
      - 8000:8000
    hostname: onclusiveml
    networks:
      - onclusive-net
    healthcheck:
      test: [CMD, curl, -f, http://serve:8000/sentiment/v1/ready]
      interval: 10s
      retries: 5
      start_period: 5s
      timeout: 10s

  # utility service: downloading the compiled model artifact that will be served
  serve-download-model:
    volumes:
      - type: bind
        source: serve/
        target: /projects/sentiment/serve/
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-serve:${IMAGE_TAG}
    command: [python, -m, src.download]
    profiles: [serve, integration, functional, load]
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
      NEPTUNE_CLIENT_MODE: read-only
      NEPTUNE_PROJECT: onclusive/sentiment
      NEPTUNE_MODEL_ID: SEN-COMPILED
      NEPTUNE_MODEL_VERSION_ID: SEN-COMPILED-46
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SEN-COMPILED-46
    hostname: onclusiveml
    networks: [onclusive-net]

  serve-debug:
    devices:
      - /dev/neuron0:/dev/neuron0
    build:
      context: ../../
      dockerfile: projects/sentiment/serve/Dockerfile
      target: ${TARGET_BUILD_STAGE:-debugger}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        PROJECT: sentiment
        COMPONENT: serve
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v23.11.3}
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-serve:${IMAGE_TAG}
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
      NEPTUNE_CLIENT_MODE: read-only
      NEPTUNE_PROJECT: onclusive/sentiment
      NEPTUNE_MODEL_ID: SEN-COMPILED
      NEPTUNE_MODEL_VERSION_ID: SEN-COMPILED-46
      ONCLUSIVEML_SERVING_LOGCONFIG_SERVICE: sentiment-serve
      ONCLUSIVEML_SERVING_LOGCONFIG_LEVEL: 10
      ONCLUSIVEML_SERVING_LOGCONFIG_JSON_FORMAT: false
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SEN-COMPILED-46
      ONCLUSIVEML_SERVING_UVICORN_APP: src.serve.__main__:model_server
      ONCLUSIVEML_SERVING_UVICORN_RELOAD: true
      ONCLUSIVEML_SERVING_UVICORN_RELOAD_DIRS: src/serve/
      ONCLUSIVEML_SERVING_UVICORN_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
      ONCLUSIVEML_TRACKING_LOGGER_LEVEL: 20 # 10=DEBUG
    profiles: [debug]
    command:
      - /bin/sh
      - -c
      - |
        python -m src.download
        python -m debugpy --listen 0.0.0.0:5678 --wait-for-client -m src.serve.__main__
    ports:
      - 5678:5678
      - 8000:8000
    hostname: onclusiveml
    networks:
      - onclusive-net

  # unit tests
  # - do NOT include model artifact
  # - do NOT include REST model server process
  serve-unit:
    volumes:
      - type: bind
        source: ${HOME}/data
        target: /projects/sentiment/serve/models
      - type: bind
        source: serve/src
        target: /projects/sentiment/serve/src
      - type: bind
        source: serve/tests
        target: /projects/sentiment/serve/tests
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-serve:${IMAGE_TAG}
    environment:
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SEN-COMPILED-46
      ONCLUSIVEML_SERVING_UVICORN_HTTP_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
      ONCLUSIVEML_TRACKING_LOGGER_LEVEL: 20 # 10=DEBUG
      NEPTUNE_PROJECT: onclusive/sentiment
      NEPTUNE_MODEL_ID: SEN-COMPILED
    command: [pytest, tests/unit, -ra, -vv, --capture=no]
    profiles: [unit]
    hostname: onclusiveml
    networks:
      - onclusive-net

  # integration tests
  # - include model artifact
  # - do NOT include REST model server process
  serve-integration:
    devices:
      - /dev/neuron0:/dev/neuron0 # needs to be different from the `serve` service device
    volumes:
      - type: bind
        source: serve/
        target: /projects/sentiment/serve/
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-serve:${IMAGE_TAG}
    command: [pytest, tests/integration, -ra, -vv, --capture=no]
    environment:
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SEN-COMPILED-46
      NEPTUNE_PROJECT: onclusive/sentiment
      NEPTUNE_MODEL_ID: SEN-COMPILED
      ONCLUSIVEML_SERVING_UVICORN_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
    profiles: [integration]
    hostname: onclusiveml
    networks:
      - onclusive-net

  # functional tests
  # - include model artifact
  # - include REST model server process
  serve-functional:
    volumes:
      - type: bind
        source: ${HOME}/data
        target: /projects/sentiment/serve/models
      - type: bind
        source: serve/src
        target: /projects/sentiment/serve/src
      - type: bind
        source: serve/tests
        target: /projects/sentiment/serve/tests
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-serve:${IMAGE_TAG}
    command: [pytest, tests/functional, -ra, -vv, --capture=no]
    environment:
      NEPTUNE_PROJECT: onclusive/sentiment
      NEPTUNE_MODEL_ID: SEN-COMPILED
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SEN-COMPILED-46
      ONCLUSIVEML_SERVING_UVICORN_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
    profiles: [functional]
    hostname: onclusiveml
    networks:
      - onclusive-net
    depends_on:
      serve:
        condition: service_healthy

  # load tests
  # - include model artifact
  # - include REST model server process
  serve-load:
    volumes:
      - type: bind
        source: serve/
        target: /projects/sentiment/serve/
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-serve:${IMAGE_TAG}
    command: [pytest, tests/load, -ra, -vv, --capture=no]
    environment:
      # serving params
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SEN-COMPILED-46
      ONCLUSIVEML_SERVING_UVICORN_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
      # load test params
      ONCLUSIVEML_SERVING_NUM_USERS: 2 # numbers of users in load test
      ONCLUSIVEML_SERVING_SPAWN_RATE: 2 # per second spawn rate of clients until `num_users` is reached
      ONCLUSIVEML_SERVING_HOST: http://serve:8000 # base url of the host
      ONCLUSIVEML_SERVING_RESET_STATS: No
      ONCLUSIVEML_SERVING_RUN_TIME: 45s
      ONCLUSIVEML_SERVING_LOGLEVEL: INFO
      NEPTUNE_PROJECT: onclusive/sentiment
      NEPTUNE_MODEL_ID: SEN-COMPILED
    profiles: [load]
    hostname: onclusiveml
    networks:
      - onclusive-net
    depends_on:
      serve:
        condition: service_healthy

  # utility service: uploading the relevant test results to the model registry
  serve-upload-results:
    volumes:
      - type: bind
        source: serve/
        target: /projects/sentiment/serve/
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-serve:${IMAGE_TAG}
    command: [python, -m, src.upload]
    profiles: [serve]
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
      NEPTUNE_CLIENT_MODE: async
      NEPTUNE_PROJECT: onclusive/sentiment
      NEPTUNE_MODEL_ID: SEN-COMPILED
      NEPTUNE_MODEL_VERSION_ID: SEN-COMPILED-46
      ONCLUSIVEML_TRACKING_BACKEND_USE_S3_BACKEND: yes
      ONCLUSIVEML_TRACKING_LOGGER_LEVEL: 10
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/SEN-COMPILED-46
      ONCLUSIVEML_SERVING_DOCKER_IMAGE_NAME: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-serve
      ONCLUSIVEML_SERVING_DOCKER_IMAGE_TAG: ${IMAGE_TAG}
      DOCKER_COMPOSE_ENVIRONMENT: ${ENVIRONMENT}
      ONCLUSIVEML_SERVING_GITHUB_REPOSITORY: development-repository
      ONCLUSIVEML_SERVING_GITHUB_ACTOR: development-actor
      ONCLUSIVEML_SERVING_GITHUB_ENV: development-env
      ONCLUSIVEML_SERVING_GITHUB_WORKFLOW: development-workflow
      ONCLUSIVEML_SERVING_GITHUB_JOB: development-job
      ONCLUSIVEML_SERVING_GITHUB_REF: development-ref
      ONCLUSIVEML_SERVING_GITHUB_BASE_REF: development-base-ref
      ONCLUSIVEML_SERVING_GITHUB_HEAD_REF: development-head-ref
      ONCLUSIVEML_SERVING_GITHUB_SHA: development-sha
      ONCLUSIVEML_SERVING_GITHUB_EVENT_NAME: development-event-name
      ONCLUSIVEML_SERVING_GITHUB_RUN_ID: development-run-id
      ONCLUSIVEML_SERVING_GITHUB_RUN_NUMBER: development-run-number
      ONCLUSIVEML_SERVING_RUNNER_ARCH: development-arch
      ONCLUSIVEML_SERVING_RUNNER_NAME: development-name
      ONCLUSIVEML_SERVING_RUNNER_OS: development-os
    hostname: onclusive-ml
    networks: [onclusive-net]

  # =============================================
  # BACKFILL
  # =============================================

  backfill:
    build:
      context: ../../
      dockerfile: projects/sentiment/backfill/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-690763002009}
        PROJECT: sentiment
        COMPONENT: backfill
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v24.1.6}
    volumes:
      - type: bind
        source: backfill/src
        target: /projects/sentiment/backfill/src
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-backfill:${IMAGE_TAG}
    entrypoint: [python, -m, src.backfill.__main__]
    profiles: [backfill]
    network_mode: service:taskmanager
    environment:
      HOST: internal.api.ml.stage.onclusive.com
      NAMESPACE: sentiment
      VERSION: 1
      API_KEY: ${INTERNAL_ML_ENDPOINT_API_KEY}
      SECURE: true
      JOB_NAME: sentiment-backfill
      RUNNER: PortableRunner
      STREAMING: true
      ARTIFACT_ENDPOINT: jobserver:8098
      JOB_ENDPOINT: jobserver:8099
      ENVIRONMENT_TYPE: LOOPBACK
      SOURCE_TOPIC: beam-input
      TARGET_TOPIC: beam-output
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: notification_consumer_group
      AUTO_OFFSET_RESET: earliest
    depends_on:
      - jobserver
      - kafka
      - zookeeper

  backfill-unit:
    volumes:
      - type: bind
        source: backfill
        target: /projects/sentiment/backfill
    image: ${AWS_ACCOUNT_ID:-690763002009}.dkr.ecr.us-east-1.amazonaws.com/sentiment-backfill:${IMAGE_TAG}
    command: [pytest, tests/unit, -ra, -vv, --capture=no, -s]
    profiles: [unit]
    environment:
      HOST: test.onclusive.com
      NAMESPACE: sentiment
      VERSION: 1
      API_KEY: test
      SECURE: true
      JOB_NAME: sentiment-backfill
      RUNNER: PortableRunner
      STREAMING: true
      ARTIFACT_ENDPOINT: jobserver:8098
      JOB_ENDPOINT: jobserver:8099
      ENVIRONMENT_TYPE: LOOPBACK
      SOURCE_TOPIC: beam-input
      TARGET_TOPIC: beam-output
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: notification_consumer_group
      AUTO_OFFSET_RESET: earliest
    hostname: onclusive-ml
    networks: [onclusive-net]

  jobmanager:
    image: apache/flink:1.16-scala_2.12-java11
    command: [jobmanager]
    ports:
      - 8081:8081
    profiles: [backfill]
    networks: [onclusive-net]
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: jobmanager
        parallelism.default: 1

  taskmanager:
    image: apache/flink:1.16-scala_2.12-java11
    scale: 1
    depends_on:
      - jobmanager
    command: [taskmanager]
    ports:
      - 8100-8200:8100-8200
    profiles: [backfill]
    networks: [onclusive-net]
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 2
        parallelism.default: 1
    volumes:
      - backfill-volume:/tmp/beam-artifact-staging

  jobserver:
    image: apache/beam_flink1.16_job_server:2.49.0
    command:
      - --flink-master=jobmanager:8081
    ports:
      - 8097:8097
      - 8098:8098
      - 8099:8099
    depends_on:
      - jobmanager
    profiles: [backfill]
    networks: [onclusive-net]
    volumes:
      - backfill-volume:/tmp/beam-artifact-staging

  zookeeper:
    image: confluentinc/cp-zookeeper
    profiles: [backfill]
    networks: [onclusive-net]
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2

  kafka:
    image: confluentinc/cp-kafka:6.1.13
    profiles: [backfill]
    networks: [onclusive-net]
    ports:
      - 9092:9092
      - 9094:9094
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,OUTSIDE://0.0.0.0:9094
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://localhost:9094
      LAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CREATE_TOPICS: beam-output:1:1,beam-input:1:1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      TOPIC_AUTO_CREATE: true

  kafka-ui:
    image: provectuslabs/kafka-ui
    profiles: [backfill]
    ports:
      - 9000:9000
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
    depends_on:
      - kafka


volumes :
  backfill-volume:

networks:
  onclusive-net:

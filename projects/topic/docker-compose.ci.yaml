---
version : '3.9'

services:
  # =============================================
  # REGISTER
  # =============================================

  register:
    build:
      context: ../../
      dockerfile: projects/topic/register/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-063759612765}
        PROJECT: topic
        COMPONENT: register
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v23.10.5}
    volumes:
      - type: bind
        source: register/src
        target: /projects/topic/register/src
    image: ${AWS_ACCOUNT_ID:-063759612765}.dkr.ecr.us-east-1.amazonaws.com/topic-register:${IMAGE_TAG:-latest}
    command: [python, -m, src.register_features]
    profiles: [register]
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    env_file: register/config/prod.env
    hostname: onclusive-ml
    networks: [onclusive-net]

  register-unit:
    volumes:
      - type: bind
        source: register/
        target: /projects/topic/register/
    image: ${AWS_ACCOUNT_ID:-063759612765}.dkr.ecr.us-east-1.amazonaws.com/topic-register:${IMAGE_TAG}
    command: [pytest, tests/unit, -ra, -vv, --capture=no]
    profiles: [register, unit]
    hostname: onclusive-ml
    networks: [onclusive-net]

  # =============================================
  # SERVE
  # =============================================

  # serving image
  serve:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              # that's the closest analogue to --gpus; provide
              # an integer amount of devices or 'all'
              count: 1
              # Devices are reserved using a list of capabilities, making
              # capabilities the only required field. A device MUST
              # satisfy all the requested capabilities for a successful
              # reservation.
              capabilities: [gpu]
    volumes:
      - serve-vol:/projects/topic/serve/models
    build:
      context: ../../
      dockerfile: projects/topic/serve/Dockerfile
      target: ${TARGET_BUILD_STAGE:-development}
      network: host
      args:
        AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID:-063759612765}
        PROJECT: topic
        COMPONENT: serve
        BASE_IMAGE_TAG: ${BASE_IMAGE_TAG:-v23.11.2}
    image: ${AWS_ACCOUNT_ID:-063759612765}.dkr.ecr.us-east-1.amazonaws.com/topic-serve:${IMAGE_TAG}
    command: [python, -m, src.serve.__main__]
    environment:
      ONCLUSIVEML_SERVING_LOGCONFIG_SERVICE: topic-serve
      ONCLUSIVEML_SERVING_LOGCONFIG_LEVEL: 10
      ONCLUSIVEML_SERVING_LOGCONFIG_JSON_FORMAT: yes
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/TOPIC-TRAINED-43
      ONCLUSIVEML_SERVING_UVICORN_APP: src.serve.__main__:model_server
      ONCLUSIVEML_SERVING_UVICORN_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
      NEPTUNE_PROJECT: onclusive/topic
      NEPTUNE_MODEL_ID: TOPIC-TRAINED
    profiles: [serve, functional, load]
    ports:
      - 8000:8000
    hostname: onclusiveml
    networks:
      - onclusive-net
    healthcheck:
      test: [CMD, curl, -f, http://serve:8000/topic/v1/ready]
      interval: 10s
      retries: 5
      start_period: 5s
      timeout: 10s

  # utility service: downloading the compiled model artifact that will be served
  serve-download-model:
    volumes:
      - serve-vol:/projects/topic/serve/models
    image: ${AWS_ACCOUNT_ID:-063759612765}.dkr.ecr.us-east-1.amazonaws.com/topic-serve:${IMAGE_TAG}
    command: [python, -m, src.download]
    profiles: [serve, integration, functional, load]
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      NEPTUNE_API_TOKEN: ${NEPTUNE_API_TOKEN}
      NEPTUNE_CLIENT_MODE: read-only
      NEPTUNE_PROJECT: onclusive/topic
      NEPTUNE_MODEL_ID: TOPIC-TRAINED
      NEPTUNE_MODEL_VERSION_ID: TOPIC-TRAINED-43
      ONCLUSIVEML_TRACKING_BACKEND_USE_S3_BACKEND: yes
      ONCLUSIVEML_TRACKING_BACKEND_S3_BACKEND_BUCKET: onclusive-model-store-stage
      ONCLUSIVEML_TRACKING_LOGGER_LEVEL: 10
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/TOPIC-TRAINED-43
    hostname: onclusiveml
    networks: [onclusive-net]

  # unit tests
  # - do NOT include model artifact
  # - do NOT include REST model server process
  serve-unit:
    image: ${AWS_ACCOUNT_ID:-063759612765}.dkr.ecr.us-east-1.amazonaws.com/topic-serve:${IMAGE_TAG}
    environment:
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/TOPIC-TRAINED-43
      ONCLUSIVEML_SERVING_UVICORN_HTTP_PORT: 8000
      ONCLUSIVEML_SERVING_API_VERSION: v1
      ONCLUSIVEML_TRACKING_LOGGER_LEVEL: 20 # 10=DEBUG
      NEPTUNE_PROJECT: onclusive/topic
      NEPTUNE_MODEL_ID: TOPIC-TRAINED
    command: [pytest, tests/unit, -ra, -vv, --capture=no]
    profiles: [unit]
    hostname: onclusiveml
    networks:
      - onclusive-net

  # functional tests
  # - include model artifact
  # - include REST model server process
  serve-functional:
    volumes:
      - serve-vol:/projects/topic/serve/models
    image: ${AWS_ACCOUNT_ID:-063759612765}.dkr.ecr.us-east-1.amazonaws.com/topic-serve:${IMAGE_TAG}
    command: [pytest, tests/functional, -ra, -vv, --capture=no]
    environment:
      ONCLUSIVEML_SERVING_MODEL_DIRECTORY: models/TOPIC-TRAINED-43
      NEPTUNE_PROJECT: onclusive/topic
      NEPTUNE_MODEL_ID: TOPIC-TRAINED
    profiles: [functional]
    hostname: onclusiveml
    networks:
      - onclusive-net
    depends_on:
      serve:
        condition: service_healthy


networks:
  onclusive-net:

volumes :
  serve-vol:
